{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 奇异值分解\n",
    "\n",
    "到目前为止，你已经学习了一些奇异值分解知识。在此 notebook 中，你将练习这方面的技巧。\n",
    "\n",
    "首先读取库和设置将在这个 notebook 中一直使用的数据。\n",
    "\n",
    "`1.` 请运行以下单元格并创建 **user_movie_subset** DataFrame。你将在此 notebook 的第一部分使用该 DataFrame。\n",
    "\n",
    "**注意：分解该矩阵需要大约 10 分钟的时间。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id  73486  75314  68646  99685\n",
      "user_id                             \n",
      "265        10.0   10.0   10.0   10.0\n",
      "1023       10.0    4.0    9.0   10.0\n",
      "1683        8.0    9.0   10.0    5.0\n",
      "6571        9.0    8.0   10.0   10.0\n",
      "11639      10.0    5.0    9.0    9.0\n",
      "13006       6.0    4.0   10.0    6.0\n",
      "14076       9.0    8.0   10.0    9.0\n",
      "14725      10.0    5.0    9.0    8.0\n",
      "23548       7.0    8.0   10.0    8.0\n",
      "24760       9.0    5.0    9.0    7.0\n",
      "28713       9.0    8.0   10.0    8.0\n",
      "30685       9.0   10.0   10.0    9.0\n",
      "34110      10.0    9.0   10.0    8.0\n",
      "34430       5.0    8.0    5.0    8.0\n",
      "35150      10.0    8.0   10.0   10.0\n",
      "43294       9.0    9.0   10.0   10.0\n",
      "46849       9.0    8.0    8.0    8.0\n",
      "50556      10.0    8.0    1.0   10.0\n",
      "51382       5.0    6.0   10.0   10.0\n",
      "51410       8.0    7.0   10.0    7.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import svd_tests as t\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('data/movies_clean.csv')\n",
    "reviews = pd.read_csv('data/reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']\n",
    "\n",
    "# Create user-by-item matrix\n",
    "user_items = reviews[['user_id', 'movie_id', 'rating']]\n",
    "user_by_movie = user_items.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "\n",
    "user_movie_subset = user_by_movie[[73486, 75314,  68646, 99685]].dropna(axis=0)\n",
    "print(user_movie_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 获得 **user_movie_subset** 矩阵后，请根据该矩阵将每个键与以下字典中的正确值相匹配。请使用字典下方的单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  There are 20 users in the dataset, which is given by the number of rows. There are 4 movies in the dataset given by the number of columns.  You can find the movies or users with the highest average ratings by taking the mean of each row or column.  Using the movies table, you can find the movie names associated with each id.  This shows the top rated movie is The Godfather!\n"
     ]
    }
   ],
   "source": [
    "# match each letter to the best statement in the dictionary below - each will be used at most once\n",
    "a = 20\n",
    "b = 68646\n",
    "c = 'The Godfather'\n",
    "d = 'Goodfellas'\n",
    "e = 265\n",
    "f = 30685\n",
    "g = 4\n",
    "\n",
    "sol_1_dict = {\n",
    "    'the number of users in the user_movie_subset': a,\n",
    "    'the number of movies in the user_movie_subset': g,\n",
    "    'the user_id with the highest average ratings given': e,\n",
    "    'the movie_id with the highest average ratings received': b,\n",
    "    'the name of the movie that received the highest average rating': c\n",
    "}\n",
    "\n",
    "\n",
    "#test dictionary here\n",
    "t.test1(sol_1_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id\n",
      "265      10.00\n",
      "1023      8.25\n",
      "1683      8.00\n",
      "6571      9.25\n",
      "11639     8.25\n",
      "13006     6.50\n",
      "14076     9.00\n",
      "14725     8.00\n",
      "23548     8.25\n",
      "24760     7.50\n",
      "28713     8.75\n",
      "30685     9.50\n",
      "34110     9.25\n",
      "34430     6.50\n",
      "35150     9.50\n",
      "43294     9.50\n",
      "46849     8.25\n",
      "50556     7.25\n",
      "51382     7.75\n",
      "51410     8.00\n",
      "dtype: float64\n",
      "movie_id\n",
      "73486    8.60\n",
      "75314    7.35\n",
      "68646    9.00\n",
      "99685    8.50\n",
      "dtype: float64\n",
      "4187    One Flew Over the Cuckoo's Nest (1975)\n",
      "Name: movie, dtype: object\n",
      "4361    Taxi Driver (1976)\n",
      "Name: movie, dtype: object\n",
      "3706    The Godfather (1972)\n",
      "Name: movie, dtype: object\n",
      "6917    Goodfellas (1990)\n",
      "Name: movie, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell for work\n",
    "# user with the highest average rating\n",
    "print(user_movie_subset.mean(axis=1))\n",
    "\n",
    "# movie with highest average rating\n",
    "print(user_movie_subset.mean(axis=0))\n",
    "\n",
    "# list of movie names\n",
    "for movie_id in [73486, 75314,  68646, 99685]:\n",
    "    print(movies[movies['movie_id'] == movie_id]['movie'])\n",
    "    \n",
    "# users by movies\n",
    "user_movie_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在你已经大致了解了我们将对其执行奇异值分解的矩阵，下面我们将进行分解。首先，回忆下要获取的每个矩阵的维度。   我们要将 **user_movie_subset** 矩阵拆分为三个矩阵：\n",
    "\n",
    "$$ U \\Sigma V^T $$\n",
    "\n",
    "\n",
    "`3.` 请根据在这节课之前的部分学到的知识，在以下字典中指出上述每个矩阵的维度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right!  We will now put this to use, so you can see how the dot product of these matrices come together to create our user item matrix.  The number of latent features will control the sigma matrix as well, and this will a square matrix that will at most be the minimum of the number of users and number of movies (in our case the minimum is the 4 movies).\n"
     ]
    }
   ],
   "source": [
    "# match each letter in the dictionary below - a letter may appear more than once.\n",
    "a = 'a number that you can choose as the number of latent features to keep'\n",
    "b = 'the number of users'\n",
    "c = 'the number of movies'\n",
    "d = 'the sum of the number of users and movies'\n",
    "e = 'the product of the number of users and movies'\n",
    "\n",
    "sol_2_dict = {\n",
    "    'the number of rows in the U matrix': b, \n",
    "    'the number of columns in the U matrix': a, \n",
    "    'the number of rows in the V transpose matrix': a, \n",
    "    'the number of columns in the V transpose matrix': c\n",
    "}\n",
    "\n",
    "#test dictionary here\n",
    "t.test2(sol_2_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在对用户-电影矩阵执行 SVD，并验证上述维度。\n",
    "\n",
    "`4.` 以下是在 NumPy 中执行 SVD 的代码。要详细了解此功能，请参阅[此文档](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.svd.html)。你发现这些矩阵的形状有什么规律？如果尝试对获得的三个对象执行点积运算，能够直接获得用户-电影矩阵吗？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20, 20), (4,), (4, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, s, vt = np.linalg.svd(user_movie_subset) # perform svd here on user_movie_subset\n",
    "u.shape, s.shape, vt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking at the dimensions of the three returned objects, we can see the following:\n",
      "\n",
      " 1. The u matrix is a square matrix with the number of rows and columns equaling the number of users. \n",
      "\n",
      " 2. The v transpose matrix is also a square matrix with the number of rows and columns equaling the number of items.\n",
      "\n",
      " 3. The sigma matrix is actually returned as just an array with 4 values, but should be a diagonal matrix.  Numpy has a diag method to help with this.  \n",
      "\n",
      " In order to set up the matrices in a way that they can be multiplied together, we have a few steps to perform: \n",
      "\n",
      " 1. Turn sigma into a square matrix with the number of latent features we would like to keep. \n",
      "\n",
      " 2. Change the columns of u and the rows of v transpose to match this number of dimensions. \n",
      "\n",
      " If we would like to exactly re-create the user-movie matrix, we could choose to keep all of the latent features.\n"
     ]
    }
   ],
   "source": [
    "# Run this cell for our thoughts on the questions posted above\n",
    "t.question4thoughts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`5.` 请利用上个问题的思路创建有 4 个潜在特征的 U、S 和 V 转置矩阵。正确创建所有三个矩阵后，请运行以下测试，表示三个矩阵的点积能够创建原始用户-电影矩阵。这些矩阵的维度应该如下所示：\n",
    "\n",
    "$$ U_{n x k} $$\n",
    "\n",
    "$$\\Sigma_{k x k} $$\n",
    "\n",
    "$$V^T_{k x m} $$\n",
    "\n",
    "其中：\n",
    "\n",
    "1. n 表示用户数\n",
    "2. k 表示潜在特征的数量（在此例中是 4 个）\n",
    "3. m 表示电影数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dimensions of u, s, and vt as necessary to use four latent features\n",
    "# update the shape of u and store in u_new\n",
    "u_new = u[:, :len(s)]\n",
    "\n",
    "# update the shape of s and store in s_new\n",
    "s_new = np.zeros((len(s), len(s)))\n",
    "s_new[:len(s), :len(s)] = np.diag(s) \n",
    "\n",
    "# Because we are using 4 latent features and there are only 4 movies, \n",
    "# vt and vt_new are the same\n",
    "vt_new = vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right! The dimensions of u should be 20 x 4, and both v transpose and sigma should be 4 x 4.  The dot product of the three matrices how equals the original user-movie matrix!\n"
     ]
    }
   ],
   "source": [
    "# Check your matrices against the solution\n",
    "assert u_new.shape == (20, 4), \"Oops!  The shape of the u matrix doesn't look right. It should be 20 by 4.\"\n",
    "assert s_new.shape == (4, 4), \"Oops!  The shape of the sigma matrix doesn't look right.  It should be 4 x 4.\"\n",
    "assert vt_new.shape == (4, 4), \"Oops! The shape of the v transpose matrix doesn't look right.  It should be 4 x 4.\"\n",
    "assert np.allclose(np.dot(np.dot(u_new, s_new), vt_new), user_movie_subset), \"Oops!  Something went wrong with the dot product.  Your result didn't reproduce the original movie_user matrix.\"\n",
    "print(\"That's right! The dimensions of u should be 20 x 4, and both v transpose and sigma should be 4 x 4.  The dot product of the three matrices how equals the original user-movie matrix!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "∑ 矩阵能够告诉我们每个潜在特征从用户-电影矩阵中捕获的原始变化性程度如何。要解释的总变化量等于对角元素的平方和。第一个分量解释的变化量等于对角线中第一个值的平方。第二个分量解释的变化量等于对角线中第二个值的平方。   \n",
    "\n",
    "`6.` 利用以上信息，你能判断仅使用前两个分量的话，能够解释原始用户-电影矩阵中的多少变化量吗？请在以下单元格中尝试一下，然后对照下个单元格中的解答检验你的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total variance in the original matrix is 5877.0.\n",
      "Ther percentage of variability captured by the first two components is 98.55%.\n"
     ]
    }
   ],
   "source": [
    "total_var = np.sum(s**2)# Total variability here\n",
    "var_exp_comp1_and_comp2 = s[0]**2 + s[1]**2 # Variability Explained by the first two components here\n",
    "perc_exp = round(var_exp_comp1_and_comp2/total_var*100, 2) # Percent of variability explained by the first two components here\n",
    "\n",
    "# Run the below to print your results\n",
    "print(\"The total variance in the original matrix is {}.\".format(total_var))\n",
    "print(\"Ther percentage of variability captured by the first two components is {}%.\".format(perc_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yup!  That all looks good!\n"
     ]
    }
   ],
   "source": [
    "assert np.round(perc_exp, 2) == 98.55, \"Oops!  That doesn't look quite right.  You should have total variability as the sum of all the squared elements in the sigma matrix.  Then just the sum of the squared first two elements is the amount explained by the first two latent features.  Try again.\"\n",
    "print(\"Yup!  That all looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`7.` 与上个问题类似，但是更改下 U、∑ 和 V 转置矩阵的形状。这次仅使用前两个分量重现用户-电影矩阵，而不使用四个分量。设置好矩阵后，请运行测试并对照解答页面检查你的矩阵。这些矩阵的维度应该如下所示：\n",
    "\n",
    "$$ U_{n x k} $$\n",
    "\n",
    "$$\\Sigma_{k x k} $$\n",
    "\n",
    "$$V^T_{k x m} $$\n",
    "\n",
    "其中：\n",
    "\n",
    "1. n 表示用户数\n",
    "2. k 表示潜在特征的数量（在此例中是 2 个）\n",
    "3. m 表示电影数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dimensions of u, s, and vt as necessary to use four latent features\n",
    "# update the shape of u and store in u_new\n",
    "k = 2\n",
    "u_2 = u[:, :k]\n",
    "\n",
    "# update the shape of s and store in s_new\n",
    "s_2 = np.zeros((k, k))\n",
    "s_2[:k, :k] = np.diag(s[:k]) \n",
    "\n",
    "# Because we are using 2 latent features, we need to update vt this time\n",
    "vt_2 = vt[:k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right! The dimensions of u should be 20 x 2, sigma should be 2 x 2, and v transpose should be 2 x 4. \n",
      "\n",
      " The question is now that we don't have all of the latent features, how well can we really re-create the original user-movie matrix?\n"
     ]
    }
   ],
   "source": [
    "# Check that your matrices are the correct shapes\n",
    "assert u_2.shape == (20, 2), \"Oops!  The shape of the u matrix doesn't look right. It should be 20 by 2.\"\n",
    "assert s_2.shape == (2, 2), \"Oops!  The shape of the sigma matrix doesn't look right.  It should be 2 x 2.\"\n",
    "assert vt_2.shape == (2, 4), \"Oops! The shape of the v transpose matrix doesn't look right.  It should be 2 x 4.\"\n",
    "print(\"That's right! The dimensions of u should be 20 x 2, sigma should be 2 x 2, and v transpose should be 2 x 4. \\n\\n The question is now that we don't have all of the latent features, how well can we really re-create the original user-movie matrix?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`8.` 使用所有 4 个潜在特征时，我们能够完全重现用户-电影矩阵。现在只有 2 个潜在特征，我们可以衡量下重现原始矩阵的效果，方法是查看点击运算生成的评分与实际评分之间的平方误差之和。仅使用两个潜在特征计算平方误差之和，并在以下单元格中对照解答页面测试你的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the dot product\n",
    "pred_ratings = np.dot(np.dot(u_2, s_2), vt_2)\n",
    "\n",
    "# Compute the squared error for each predicted vs. actual rating\n",
    "sum_square_errs = np.sum(np.sum((user_movie_subset - pred_ratings)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "669.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_movie_subset.sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That looks right!  Nice job!\n"
     ]
    }
   ],
   "source": [
    "# Check against the solution\n",
    "assert np.round(sum_square_errs, 2) == 85.34, \"Oops!  That doesn't look quite right.  You should return a single number for the whole matrix.\"\n",
    "print(\"That looks right!  Nice job!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这时候你可能会想.. 为何要选择一个不能返回包含所有原始评分的完整用户-电影矩阵的 k。问得好。一个是计算原因，我们肯定想要降低数据的维度，但这不是我们希望 k 小于电影数量和用户数量的主要原因。\n",
    "\n",
    "我们暂时先思维往后退一步。在我们刚刚查看的这个示例中，矩阵很整洁。每个用户-电影组合都有一个评分。**没有丢失任何值。**但是从上节课我们知道，用户-电影矩阵有很多值丢失了。  \n",
    "\n",
    "下面是与我们刚刚对其执行 SVD 的矩阵相似的矩阵：\n",
    "\n",
    "<img src=\"imgs/nice_ex.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "现实中：\n",
    "\n",
    "<img src=\"imgs/real_ex.png\" width=\"400\" height=\"400\">\n",
    "\n",
    "\n",
    "所以，如果保留所有 k 个潜在特征，∑ 矩阵中值更小的潜在特征很有可能解释的变化性是由噪点导致的，而不是信号导致的。此外，如果我们在重构原始用户-电影矩阵时使用“有噪点的”潜在特征，可能会导致评分比仅使用与信号相关的潜在特征得出的评分更糟糕。   \n",
    "\n",
    "`9.` 我们对缺少值的矩阵执行 SVD，使数据更加真实。下面我向矩阵中添加了一个新的用户，该用户尚未对所有四部电影都评分。请尝试对新的矩阵执行 SVD。会发生什么？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5a75d7cf58da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Try svd with this new matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_movie_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1611\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1612\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1613\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1614\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda3/lib/python3.7/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36m_raise_linalgerror_svd_nonconvergence\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_svd_nonconvergence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLinAlgError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SVD did not converge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_raise_linalgerror_lstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge"
     ]
    }
   ],
   "source": [
    "# This line adds one nan value as the very first entry in our matrix\n",
    "user_movie_subset.iloc[0, 0] = np.nan\n",
    "\n",
    "# Try svd with this new matrix\n",
    "u, s, vt = np.linalg.svd(user_movie_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**请在这里填写答案。** \n",
    "\n",
    "\n",
    "```python\n",
    "Even with just one nan value we cannot perform SVD! This is going to be a huge problem, because our real dataset has nan values everywhere! This is where FunkSVD comes in to help.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
