{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 效果检验\n",
    "\n",
    "在上个 notebook 中，你创建了一个即使缺少大量值也能正常运行的 SVD 函数。太棒了！问题是，这个函数的实际效果如何？\n",
    "\n",
    "在此 notebook 中，我们将完全模拟真实的情况，并微调我们的推荐系统。  \n",
    "\n",
    "请运行以下单元格来读取数据并开始。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('data/movies_clean.csv')\n",
    "reviews = pd.read_csv('data/reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.请对 **reviews** dataframe 执行以下任务，创建一个训练集和验证集，并使用**离线**验证技巧测试 SVD 算法的效果。\n",
    "\n",
    " * 从最早到最新对 reviews dataframe 排序 \n",
    " * 从数据集中提取前 10000 条评论\n",
    " * 将这 10000 条评论中的前 8000 条作为训练数据 \n",
    " * 将这 10000 条评论中的后 2000 条作为测试数据\n",
    " * 返回训练和测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test(reviews, order_by, training_size, testing_size):\n",
    "    '''    \n",
    "    INPUT:\n",
    "    reviews - (pandas df) dataframe to split into train and test\n",
    "    order_by - (string) column name to sort by\n",
    "    training_size - (int) number of rows in training set\n",
    "    testing_size - (int) number of columns in the test set\n",
    "    \n",
    "    OUTPUT:\n",
    "    training_df -  (pandas df) dataframe of the training set\n",
    "    validation_df - (pandas df) dataframe of the test set\n",
    "    '''\n",
    "    reviews_new = reviews.sort_values(order_by)\n",
    "    training_df = reviews_new.head(training_size)\n",
    "    validation_df = reviews_new.iloc[training_size:training_size+testing_size]\n",
    "    \n",
    "    return training_df, validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing to change in this or the next cell\n",
    "# Use our function to create training and test datasets\n",
    "train_df, val_df = create_train_test(reviews, 'date', 8000, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job!  Looks like you have written a function that provides training and validation dataframes for you to use in the next steps.\n"
     ]
    }
   ],
   "source": [
    "# Make sure the dataframes we are using are the right shape\n",
    "assert train_df.shape[0] == 8000, \"The number of rows doesn't look right in the training dataset.\"\n",
    "assert val_df.shape[0] == 2000, \"The number of rows doesn't look right in the validation dataset\"\n",
    "assert str(train_df.tail(1)['date']).split()[1] == '2013-03-15', \"The last date in the training dataset doesn't look like what we expected.\"\n",
    "assert str(val_df.tail(1)['date']).split()[1] == '2013-03-18', \"The last date in the validation dataset doesn't look like what we expected.\"\n",
    "print(\"Nice job!  Looks like you have written a function that provides training and validation dataframes for you to use in the next steps.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在现实中，我们可能会将到最后日期的所有数据当做训练数据。然后我们将查看出现在测试数据集中的每个新评分效果如何。\n",
    "\n",
    "下面是在之前的示例中创建的一个能运行的函数示例，你可以使用该函数，或者替换成你自己的函数。\n",
    "\n",
    "`2.` 使用以下超参数将函数拟合到训练数据：15 个潜在特征，学习速率为 0.005，迭代 250 次。运行需要一段时间，如果你想加快运行速度，可以选择更少的潜在特征、更高的学习速率，或者更少的迭代次数。  \n",
    "\n",
    "**注意：**你可以散散步，休息一下，或者打个电话。不需要更改以下代码，除非你想更快地获得结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunkSVD(ratings_mat, latent_features=12, learning_rate=0.0001, iters=100):\n",
    "    '''\n",
    "    This function performs matrix factorization using a basic form of FunkSVD with no regularization\n",
    "    \n",
    "    INPUT:\n",
    "    ratings_mat - (numpy array) a matrix with users as rows, movies as columns, and ratings as values\n",
    "    latent_features - (int) the number of latent features used\n",
    "    learning_rate - (float) the learning rate \n",
    "    iters - (int) the number of iterations\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_mat - (numpy array) a user by latent feature matrix\n",
    "    movie_mat - (numpy array) a latent feature by movie matrix\n",
    "    '''\n",
    "    \n",
    "    # Set up useful values to be used through the rest of the function\n",
    "    n_users = ratings_mat.shape[0]\n",
    "    n_movies = ratings_mat.shape[1]\n",
    "    num_ratings = np.count_nonzero(~np.isnan(ratings_mat))\n",
    "    \n",
    "    # initialize the user and movie matrices with random values\n",
    "    user_mat = np.random.rand(n_users, latent_features)\n",
    "    movie_mat = np.random.rand(latent_features, n_movies)\n",
    "    \n",
    "    # initialize sse at 0 for first iteration\n",
    "    sse_accum = 0\n",
    "    \n",
    "    # keep track of iteration and MSE\n",
    "    print(\"Optimizaiton Statistics\")\n",
    "    print(\"Iterations | Mean Squared Error \")\n",
    "    \n",
    "    # for each iteration\n",
    "    for iteration in range(iters):\n",
    "\n",
    "        # update our sse\n",
    "        old_sse = sse_accum\n",
    "        sse_accum = 0\n",
    "        \n",
    "        # For each user-movie pair\n",
    "        for i in range(n_users):\n",
    "            for j in range(n_movies):\n",
    "                \n",
    "                # if the rating exists\n",
    "                if ratings_mat[i, j] > 0:\n",
    "                    \n",
    "                    # compute the error as the actual minus the dot product of the user and movie latent features\n",
    "                    diff = ratings_mat[i, j] - np.dot(user_mat[i, :], movie_mat[:, j])\n",
    "                    \n",
    "                    # Keep track of the sum of squared errors for the matrix\n",
    "                    sse_accum += diff**2\n",
    "                    \n",
    "                    # update the values in each matrix in the direction of the gradient\n",
    "                    for k in range(latent_features):\n",
    "                        user_mat[i, k] += learning_rate * (2*diff*movie_mat[k, j])\n",
    "                        movie_mat[k, j] += learning_rate * (2*diff*user_mat[i, k])\n",
    "\n",
    "        # print results\n",
    "        print(\"%d \\t\\t %f\" % (iteration+1, sse_accum / num_ratings))\n",
    "        \n",
    "    return user_mat, movie_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 10.654655\n",
      "2 \t\t 5.905065\n",
      "3 \t\t 4.119757\n",
      "4 \t\t 3.084676\n",
      "5 \t\t 2.406248\n",
      "6 \t\t 1.927842\n",
      "7 \t\t 1.573788\n",
      "8 \t\t 1.302788\n",
      "9 \t\t 1.090150\n",
      "10 \t\t 0.920094\n",
      "11 \t\t 0.782039\n",
      "12 \t\t 0.668619\n",
      "13 \t\t 0.574546\n",
      "14 \t\t 0.495920\n",
      "15 \t\t 0.429788\n",
      "16 \t\t 0.373870\n",
      "17 \t\t 0.326367\n",
      "18 \t\t 0.285840\n",
      "19 \t\t 0.251128\n",
      "20 \t\t 0.221281\n",
      "21 \t\t 0.195527\n",
      "22 \t\t 0.173228\n",
      "23 \t\t 0.153860\n",
      "24 \t\t 0.136987\n",
      "25 \t\t 0.122248\n",
      "26 \t\t 0.109338\n",
      "27 \t\t 0.098003\n",
      "28 \t\t 0.088025\n",
      "29 \t\t 0.079221\n",
      "30 \t\t 0.071436\n",
      "31 \t\t 0.064535\n",
      "32 \t\t 0.058404\n",
      "33 \t\t 0.052946\n",
      "34 \t\t 0.048077\n",
      "35 \t\t 0.043723\n",
      "36 \t\t 0.039823\n",
      "37 \t\t 0.036322\n",
      "38 \t\t 0.033174\n",
      "39 \t\t 0.030338\n",
      "40 \t\t 0.027779\n",
      "41 \t\t 0.025465\n",
      "42 \t\t 0.023370\n",
      "43 \t\t 0.021470\n",
      "44 \t\t 0.019745\n",
      "45 \t\t 0.018176\n",
      "46 \t\t 0.016748\n",
      "47 \t\t 0.015445\n",
      "48 \t\t 0.014256\n",
      "49 \t\t 0.013170\n",
      "50 \t\t 0.012175\n",
      "51 \t\t 0.011265\n",
      "52 \t\t 0.010430\n",
      "53 \t\t 0.009663\n",
      "54 \t\t 0.008959\n",
      "55 \t\t 0.008312\n",
      "56 \t\t 0.007716\n",
      "57 \t\t 0.007167\n",
      "58 \t\t 0.006661\n",
      "59 \t\t 0.006195\n",
      "60 \t\t 0.005764\n",
      "61 \t\t 0.005366\n",
      "62 \t\t 0.004998\n",
      "63 \t\t 0.004657\n",
      "64 \t\t 0.004342\n",
      "65 \t\t 0.004050\n",
      "66 \t\t 0.003779\n",
      "67 \t\t 0.003528\n",
      "68 \t\t 0.003295\n",
      "69 \t\t 0.003079\n",
      "70 \t\t 0.002878\n",
      "71 \t\t 0.002691\n",
      "72 \t\t 0.002517\n",
      "73 \t\t 0.002355\n",
      "74 \t\t 0.002205\n",
      "75 \t\t 0.002065\n",
      "76 \t\t 0.001934\n",
      "77 \t\t 0.001813\n",
      "78 \t\t 0.001699\n",
      "79 \t\t 0.001594\n",
      "80 \t\t 0.001495\n",
      "81 \t\t 0.001403\n",
      "82 \t\t 0.001317\n",
      "83 \t\t 0.001236\n",
      "84 \t\t 0.001161\n",
      "85 \t\t 0.001091\n",
      "86 \t\t 0.001025\n",
      "87 \t\t 0.000964\n",
      "88 \t\t 0.000906\n",
      "89 \t\t 0.000852\n",
      "90 \t\t 0.000802\n",
      "91 \t\t 0.000755\n",
      "92 \t\t 0.000711\n",
      "93 \t\t 0.000669\n",
      "94 \t\t 0.000630\n",
      "95 \t\t 0.000594\n",
      "96 \t\t 0.000560\n",
      "97 \t\t 0.000527\n",
      "98 \t\t 0.000497\n",
      "99 \t\t 0.000469\n",
      "100 \t\t 0.000442\n",
      "101 \t\t 0.000418\n",
      "102 \t\t 0.000394\n",
      "103 \t\t 0.000372\n",
      "104 \t\t 0.000351\n",
      "105 \t\t 0.000332\n",
      "106 \t\t 0.000314\n",
      "107 \t\t 0.000296\n",
      "108 \t\t 0.000280\n",
      "109 \t\t 0.000265\n",
      "110 \t\t 0.000250\n",
      "111 \t\t 0.000237\n",
      "112 \t\t 0.000224\n",
      "113 \t\t 0.000212\n",
      "114 \t\t 0.000201\n",
      "115 \t\t 0.000190\n",
      "116 \t\t 0.000180\n",
      "117 \t\t 0.000170\n",
      "118 \t\t 0.000161\n",
      "119 \t\t 0.000153\n",
      "120 \t\t 0.000145\n",
      "121 \t\t 0.000137\n",
      "122 \t\t 0.000130\n",
      "123 \t\t 0.000124\n",
      "124 \t\t 0.000117\n",
      "125 \t\t 0.000111\n",
      "126 \t\t 0.000106\n",
      "127 \t\t 0.000100\n",
      "128 \t\t 0.000095\n",
      "129 \t\t 0.000090\n",
      "130 \t\t 0.000086\n",
      "131 \t\t 0.000081\n",
      "132 \t\t 0.000077\n",
      "133 \t\t 0.000074\n",
      "134 \t\t 0.000070\n",
      "135 \t\t 0.000066\n",
      "136 \t\t 0.000063\n",
      "137 \t\t 0.000060\n",
      "138 \t\t 0.000057\n",
      "139 \t\t 0.000054\n",
      "140 \t\t 0.000052\n",
      "141 \t\t 0.000049\n",
      "142 \t\t 0.000047\n",
      "143 \t\t 0.000045\n",
      "144 \t\t 0.000042\n",
      "145 \t\t 0.000040\n",
      "146 \t\t 0.000039\n",
      "147 \t\t 0.000037\n",
      "148 \t\t 0.000035\n",
      "149 \t\t 0.000033\n",
      "150 \t\t 0.000032\n",
      "151 \t\t 0.000030\n",
      "152 \t\t 0.000029\n",
      "153 \t\t 0.000028\n",
      "154 \t\t 0.000026\n",
      "155 \t\t 0.000025\n",
      "156 \t\t 0.000024\n",
      "157 \t\t 0.000023\n",
      "158 \t\t 0.000022\n",
      "159 \t\t 0.000021\n",
      "160 \t\t 0.000020\n",
      "161 \t\t 0.000019\n",
      "162 \t\t 0.000018\n",
      "163 \t\t 0.000017\n",
      "164 \t\t 0.000016\n",
      "165 \t\t 0.000016\n",
      "166 \t\t 0.000015\n",
      "167 \t\t 0.000014\n",
      "168 \t\t 0.000014\n",
      "169 \t\t 0.000013\n",
      "170 \t\t 0.000013\n",
      "171 \t\t 0.000012\n",
      "172 \t\t 0.000011\n",
      "173 \t\t 0.000011\n",
      "174 \t\t 0.000010\n",
      "175 \t\t 0.000010\n",
      "176 \t\t 0.000010\n",
      "177 \t\t 0.000009\n",
      "178 \t\t 0.000009\n",
      "179 \t\t 0.000008\n",
      "180 \t\t 0.000008\n",
      "181 \t\t 0.000008\n",
      "182 \t\t 0.000007\n",
      "183 \t\t 0.000007\n",
      "184 \t\t 0.000007\n",
      "185 \t\t 0.000006\n",
      "186 \t\t 0.000006\n",
      "187 \t\t 0.000006\n",
      "188 \t\t 0.000006\n",
      "189 \t\t 0.000005\n",
      "190 \t\t 0.000005\n",
      "191 \t\t 0.000005\n",
      "192 \t\t 0.000005\n",
      "193 \t\t 0.000005\n",
      "194 \t\t 0.000004\n",
      "195 \t\t 0.000004\n",
      "196 \t\t 0.000004\n",
      "197 \t\t 0.000004\n",
      "198 \t\t 0.000004\n",
      "199 \t\t 0.000004\n",
      "200 \t\t 0.000003\n",
      "201 \t\t 0.000003\n",
      "202 \t\t 0.000003\n",
      "203 \t\t 0.000003\n",
      "204 \t\t 0.000003\n",
      "205 \t\t 0.000003\n",
      "206 \t\t 0.000003\n",
      "207 \t\t 0.000003\n",
      "208 \t\t 0.000002\n",
      "209 \t\t 0.000002\n",
      "210 \t\t 0.000002\n",
      "211 \t\t 0.000002\n",
      "212 \t\t 0.000002\n",
      "213 \t\t 0.000002\n",
      "214 \t\t 0.000002\n",
      "215 \t\t 0.000002\n",
      "216 \t\t 0.000002\n",
      "217 \t\t 0.000002\n",
      "218 \t\t 0.000002\n",
      "219 \t\t 0.000002\n",
      "220 \t\t 0.000002\n",
      "221 \t\t 0.000001\n",
      "222 \t\t 0.000001\n",
      "223 \t\t 0.000001\n",
      "224 \t\t 0.000001\n",
      "225 \t\t 0.000001\n",
      "226 \t\t 0.000001\n",
      "227 \t\t 0.000001\n",
      "228 \t\t 0.000001\n",
      "229 \t\t 0.000001\n",
      "230 \t\t 0.000001\n",
      "231 \t\t 0.000001\n",
      "232 \t\t 0.000001\n",
      "233 \t\t 0.000001\n",
      "234 \t\t 0.000001\n",
      "235 \t\t 0.000001\n",
      "236 \t\t 0.000001\n",
      "237 \t\t 0.000001\n",
      "238 \t\t 0.000001\n",
      "239 \t\t 0.000001\n",
      "240 \t\t 0.000001\n",
      "241 \t\t 0.000001\n",
      "242 \t\t 0.000001\n",
      "243 \t\t 0.000001\n",
      "244 \t\t 0.000001\n",
      "245 \t\t 0.000001\n",
      "246 \t\t 0.000001\n",
      "247 \t\t 0.000001\n",
      "248 \t\t 0.000001\n",
      "249 \t\t 0.000001\n",
      "250 \t\t 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Create user-by-item matrix - nothing to do here\n",
    "train_user_item = train_df[['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "train_data_df = train_user_item.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "train_data_np = np.array(train_data_df)\n",
    "\n",
    "# Fit FunkSVD with the specified hyper parameters to the training data\n",
    "user_mat, movie_mat = FunkSVD(train_data_np, latent_features=15, learning_rate=0.005, iters=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建 **user_mat** 和 **movie_mat** 之后，我们可以计算用户对应的行和电影对应的列之间的点积，从而预测用户对电影的评分。\n",
    "\n",
    "`3.` 请按照下面的注释完成 **predict_rating** 函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(user_matrix, movie_matrix, user_id, movie_id):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_matrix - user by latent factor matrix\n",
    "    movie_matrix - latent factor by movie matrix\n",
    "    user_id - the user_id from the reviews df\n",
    "    movie_id - the movie_id according the movies df\n",
    "    \n",
    "    OUTPUT:\n",
    "    pred - the predicted rating for user_id-movie_id according to FunkSVD\n",
    "    '''\n",
    "    # Use the training data to create a series of users and movies that matches the ordering in training data\n",
    "    user_ids_series = np.array(train_data_df.index)\n",
    "    movie_ids_series = np.array(train_data_df.columns)\n",
    "    \n",
    "    # User row and Movie Column\n",
    "    user_row = np.where(user_ids_series == user_id)[0][0]\n",
    "    movie_col = np.where(movie_ids_series == movie_id)[0][0]\n",
    "    \n",
    "    # Take dot product of that row and column in U and V to make prediction\n",
    "    pred = np.dot(user_matrix[user_row, :], movie_matrix[:, movie_col])\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.179391514296607"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function with the first user-movie in the user-movie matrix (notice this is a nan)\n",
    "pred_val = predict_rating(user_mat, movie_mat, 8, 2844)\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在你已经能够做出预测了。但是如果能获取关于用户、电影和评分的描述就更好了。\n",
    "\n",
    "`4.` 请按照下面的注释完成 **predict_rating**。  \n",
    "\n",
    "**注意：**返回的片名格式有点乱，我在解答中稍微调整了下代码，使格式更清晰。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction_summary(user_id, movie_id, prediction):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id from the reviews df\n",
    "    movie_id - the movie_id according the movies df\n",
    "    prediction - the predicted rating for user_id-movie_id\n",
    "    '''\n",
    "    movie_name = str(movies[movies['movie_id'] == movie_id]['movie']) [5:]\n",
    "    movie_name = movie_name.replace('\\nName: movie, dtype: object', '')\n",
    "    print(\"For user {} we predict a {} rating for the movie {}.\".format(user_id, round(prediction, 2), str(movie_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user 8 we predict a 7.18 rating for the movie  Fantômas - À l'ombre de la guillotine (1913).\n"
     ]
    }
   ],
   "source": [
    "# Test your function the the results of the previous function\n",
    "print_prediction_summary(8, 2844, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们已经能够预测评分了，下面我们将检验函数对已经存在的评分的预测效果。这样就能判断我们获取潜在特征的效果，以及日后利用潜在特征做出预测的能力。\n",
    "\n",
    "`5.` 对于 **val_df** 数据集中的每个用户-电影评分，请比较实际评分与预测评分。预测效果如何？遇到任何问题吗？如果遇到了，是什么问题？请根据下面的文档字符串和注释回答这些问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_comparison(val_df, num_preds):\n",
    "    '''\n",
    "    INPUT:\n",
    "    val_df - the validation dataset created in the third cell above\n",
    "    num_preds - (int) the number of rows (going in order) you would like to make predictions for\n",
    "    \n",
    "    OUTPUT:\n",
    "    Nothing returned - print a statement about the prediciton made for each row of val_df from row 0 to num_preds\n",
    "    '''\n",
    "    val_users = np.array(val_df['user_id'])\n",
    "    val_movies = np.array(val_df['movie_id'])\n",
    "    val_ratings = np.array(val_df['rating'])\n",
    "    \n",
    "    \n",
    "    for idx in range(num_preds):\n",
    "        pred = predict_rating(user_mat, movie_mat, val_users[idx], val_movies[idx])\n",
    "        print(\"The actual rating for user {} on movie {} is {}.\\n While the predicted rating is {}.\".format(val_users[idx], val_movies[idx], val_ratings[idx], round(pred))) \n",
    "\n",
    "        \n",
    "# Perform the predicted vs. actual for the first 6 rows.  How does it look?\n",
    "validation_comparison(val_df, 6)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the predicted vs. actual for the first 7 rows.  What happened?\n",
    "validation_comparison(val_df, 7)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 解释下为何会发生所发生的情况。**\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
