{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实施 FunkSVD\n",
    "\n",
    "在此 notebook 中，我们将自己编写实施 FunkSVD 的函数，它会遵守你在上个视频中看到的步骤。如果你认为你还没有准备好自己完成这个任务，可以跳到下个视频，观看我是如何完成这些步骤的。\n",
    "\n",
    "我们将用之前使用的数据子集检测我们的算法。首先请运行以下单元格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10. 10. 10. 10.]\n",
      " [10.  4.  9. 10.]\n",
      " [ 8.  9. 10.  5.]\n",
      " [ 9.  8. 10. 10.]\n",
      " [10.  5.  9.  9.]\n",
      " [ 6.  4. 10.  6.]\n",
      " [ 9.  8. 10.  9.]\n",
      " [10.  5.  9.  8.]\n",
      " [ 7.  8. 10.  8.]\n",
      " [ 9.  5.  9.  7.]\n",
      " [ 9.  8. 10.  8.]\n",
      " [ 9. 10. 10.  9.]\n",
      " [10.  9. 10.  8.]\n",
      " [ 5.  8.  5.  8.]\n",
      " [10.  8. 10. 10.]\n",
      " [ 9.  9. 10. 10.]\n",
      " [ 9.  8.  8.  8.]\n",
      " [10.  8.  1. 10.]\n",
      " [ 5.  6. 10. 10.]\n",
      " [ 8.  7. 10.  7.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "import svd_tests as t\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('data/movies_clean.csv')\n",
    "reviews = pd.read_csv('data/reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']\n",
    "\n",
    "# Create user-by-item matrix\n",
    "user_items = reviews[['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "user_by_movie = user_items.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "\n",
    "# Create data subset\n",
    "user_movie_subset = user_by_movie[[73486, 75314,  68646, 99685]].dropna(axis=0)\n",
    "ratings_mat = np.matrix(user_movie_subset)\n",
    "print(ratings_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`1.` 你将使用 **user_movie_subset** 矩阵演示你的 FunkSVD 算法将收敛。在以下单元格中，请参考注释和文档字符串编写你自己的 FunkSVD 函数。你也可以自己完成这些函数，不参考注释部分。你可以随意增减函数代码，使你的代码能正常运行。 \n",
    "\n",
    "**注意：**此版矩阵分解没有 ∑ 矩阵。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FunkSVD(ratings_mat, latent_features=4, learning_rate=0.0001, iters=100):\n",
    "    '''\n",
    "    This function performs matrix factorization using a basic form of FunkSVD with no regularization\n",
    "    \n",
    "    INPUT:\n",
    "    ratings_mat - (numpy array) a matrix with users as rows, movies as columns, and ratings as values\n",
    "    latent_features - (int) the number of latent features used\n",
    "    learning_rate - (float) the learning rate \n",
    "    iters - (int) the number of iterations\n",
    "    \n",
    "    OUTPUT:\n",
    "    user_mat - (numpy array) a user by latent feature matrix\n",
    "    movie_mat - (numpy array) a latent feature by movie matrix\n",
    "    '''\n",
    "    \n",
    "    # Set up useful values to be used through the rest of the function\n",
    "    n_users = ratings_mat.shape[0]\n",
    "    n_movies = ratings_mat.shape[1]\n",
    "    num_ratings = np.count_nonzero(~np.isnan(ratings_mat))\n",
    "    \n",
    "    # initialize the user and movie matrices with random values\n",
    "    user_mat = np.random.rand(n_users, latent_features)\n",
    "    movie_mat = np.random.rand(latent_features, n_movies)\n",
    "    \n",
    "    # initialize sse at 0 for first iteration\n",
    "    sse_accum = 0 # sum of squared errors\n",
    "    \n",
    "    # header for running results\n",
    "    print(\"Optimizaiton Statistics\")\n",
    "    print(\"Iterations | Mean Squared Error \")\n",
    "    \n",
    "    # for each iteration\n",
    "    for iteration in range(iters):\n",
    "\n",
    "        # update our sse\n",
    "        old_sse = sse_accum\n",
    "        sse_accum = 0\n",
    "        \n",
    "        # For each user-movie pair\n",
    "        for i in range(n_users):\n",
    "            for j in range(n_movies):\n",
    "                \n",
    "                # if the rating exists\n",
    "                if ratings_mat[i, j] > 0:\n",
    "                    \n",
    "                    # compute the error as the actual minus the dot product of the user and movie latent features\n",
    "                    diff = ratings_mat[i, j] - np.dot(user_mat[i, :], movie_mat[:, j])\n",
    "                    \n",
    "                    # Keep track of the sum of squared errors for the matrix\n",
    "                    sse_accum += diff**2\n",
    "                    \n",
    "                    # update the values in each matrix in the direction of the gradient\n",
    "                    for k in range(latent_features):\n",
    "                        user_mat[i, k] += learning_rate * (2*diff*movie_mat[k, j])\n",
    "                        movie_mat[k, j] += learning_rate * (2*diff*user_mat[i, k])\n",
    "\n",
    "        # print results for iteration\n",
    "        print(\"%d \\t\\t %f\" % (iteration+1, sse_accum / num_ratings))\n",
    "        \n",
    "    return user_mat, movie_mat "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` 请在 **user_movie_subset** 数据集上尝试你的函数。先将潜在特征设为 4 个，学习速率设为 0.005，并迭代 10 次。在计算生成的 U 和 V 矩阵的点积时，生成的 **user_movie** 矩阵与原始数据子集有何区别？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 43.626020\n",
      "2 \t\t 14.194749\n",
      "3 \t\t 3.625608\n",
      "4 \t\t 2.669425\n",
      "5 \t\t 2.601501\n",
      "6 \t\t 2.564697\n",
      "7 \t\t 2.530203\n",
      "8 \t\t 2.493908\n",
      "9 \t\t 2.454667\n",
      "10 \t\t 2.412149\n"
     ]
    }
   ],
   "source": [
    "# use your function with 4 latent features, lr of 0.005 and 10 iterations\n",
    "user_mat, movie_mat = FunkSVD(ratings_mat, latent_features=4, learning_rate=0.005, iters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10.23662119  8.85714107 10.82659132  9.86997579]\n",
      " [ 9.25684029  6.6193294   8.84262651  9.12802047]\n",
      " [ 7.79708888  7.33448212  8.43838502  7.40091712]\n",
      " [ 9.6361636   7.93495983  9.82330193  9.91542183]\n",
      " [ 8.64005437  7.17047691  9.03195638  8.58601546]\n",
      " [ 6.70021278  6.14321055  7.11582045  6.94548669]\n",
      " [ 9.03882346  8.12897516  9.6859096   9.25072063]\n",
      " [ 8.40193385  7.24698665  8.68957727  7.99570172]\n",
      " [ 8.20407268  7.43362156  8.71602979  8.81309668]\n",
      " [ 7.96678578  6.5760213   8.17079396  7.50712166]\n",
      " [ 9.1716272   7.70095496  9.29621362  8.74680998]\n",
      " [ 9.62436225  8.48247782  9.95160609  9.59435203]\n",
      " [ 9.33425151  8.48506527  9.92757038  8.82599989]\n",
      " [ 6.10939452  6.53697902  7.00115327  6.45121096]\n",
      " [ 9.91903841  8.01081303 10.14395805 10.00173508]\n",
      " [ 9.43717628  8.81168894 10.14800659  9.81770043]\n",
      " [ 8.21217544  7.3984771   8.57495184  8.35884748]\n",
      " [ 7.2734385   5.72355046  7.20389651  7.48187682]\n",
      " [ 8.10541489  7.7384182   8.85209573  8.24960126]\n",
      " [ 8.09004224  7.01990086  8.57078746  8.15497411]]\n",
      "[[10. 10. 10. 10.]\n",
      " [10.  4.  9. 10.]\n",
      " [ 8.  9. 10.  5.]\n",
      " [ 9.  8. 10. 10.]\n",
      " [10.  5.  9.  9.]\n",
      " [ 6.  4. 10.  6.]\n",
      " [ 9.  8. 10.  9.]\n",
      " [10.  5.  9.  8.]\n",
      " [ 7.  8. 10.  8.]\n",
      " [ 9.  5.  9.  7.]\n",
      " [ 9.  8. 10.  8.]\n",
      " [ 9. 10. 10.  9.]\n",
      " [10.  9. 10.  8.]\n",
      " [ 5.  8.  5.  8.]\n",
      " [10.  8. 10. 10.]\n",
      " [ 9.  9. 10. 10.]\n",
      " [ 9.  8.  8.  8.]\n",
      " [10.  8.  1. 10.]\n",
      " [ 5.  6. 10. 10.]\n",
      " [ 8.  7. 10.  7.]]\n"
     ]
    }
   ],
   "source": [
    "#Compare the predicted and actual results\n",
    "print(np.dot(user_mat, movie_mat))\n",
    "print(ratings_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**请在此处填写你的结论。**\n",
    "**The predicted ratings from the dot product are already starting to look a lot like the original data values even after only 10 iterations.  You can see some extreme low values that are not captured well yet.  The 5 in the second to last row in the first column is predicted as an 8, and the 4 in the second row and second column is predicted to be a 7.  Clearly the model is not done learning, but things are looking good.**\n",
    "\n",
    "`3.` 再在 **user_movie_subset** 数据集上尝试你的函数。这次潜在特征为 4 个，学习速率设为 0.005。但是，迭代次数提高到 250 次。在计算生成的 U 和 V 矩阵的点积时，生成的 **user_movie** 矩阵与原始数据子集有何区别？迭代 250 次后，误差会怎样？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 47.186496\n",
      "2 \t\t 17.219530\n",
      "3 \t\t 4.348557\n",
      "4 \t\t 2.844661\n",
      "5 \t\t 2.754914\n",
      "6 \t\t 2.736003\n",
      "7 \t\t 2.723188\n",
      "8 \t\t 2.709995\n",
      "9 \t\t 2.695118\n",
      "10 \t\t 2.678185\n",
      "11 \t\t 2.658886\n",
      "12 \t\t 2.636826\n",
      "13 \t\t 2.611525\n",
      "14 \t\t 2.582438\n",
      "15 \t\t 2.548970\n",
      "16 \t\t 2.510488\n",
      "17 \t\t 2.466348\n",
      "18 \t\t 2.415916\n",
      "19 \t\t 2.358613\n",
      "20 \t\t 2.293963\n",
      "21 \t\t 2.221656\n",
      "22 \t\t 2.141622\n",
      "23 \t\t 2.054100\n",
      "24 \t\t 1.959700\n",
      "25 \t\t 1.859446\n",
      "26 \t\t 1.754769\n",
      "27 \t\t 1.647454\n",
      "28 \t\t 1.539527\n",
      "29 \t\t 1.433097\n",
      "30 \t\t 1.330170\n",
      "31 \t\t 1.232472\n",
      "32 \t\t 1.141313\n",
      "33 \t\t 1.057512\n",
      "34 \t\t 0.981395\n",
      "35 \t\t 0.912855\n",
      "36 \t\t 0.851446\n",
      "37 \t\t 0.796500\n",
      "38 \t\t 0.747231\n",
      "39 \t\t 0.702815\n",
      "40 \t\t 0.662461\n",
      "41 \t\t 0.625437\n",
      "42 \t\t 0.591101\n",
      "43 \t\t 0.558902\n",
      "44 \t\t 0.528382\n",
      "45 \t\t 0.499171\n",
      "46 \t\t 0.470981\n",
      "47 \t\t 0.443597\n",
      "48 \t\t 0.416870\n",
      "49 \t\t 0.390711\n",
      "50 \t\t 0.365080\n",
      "51 \t\t 0.339979\n",
      "52 \t\t 0.315449\n",
      "53 \t\t 0.291553\n",
      "54 \t\t 0.268376\n",
      "55 \t\t 0.246011\n",
      "56 \t\t 0.224557\n",
      "57 \t\t 0.204108\n",
      "58 \t\t 0.184748\n",
      "59 \t\t 0.166546\n",
      "60 \t\t 0.149553\n",
      "61 \t\t 0.133801\n",
      "62 \t\t 0.119298\n",
      "63 \t\t 0.106036\n",
      "64 \t\t 0.093983\n",
      "65 \t\t 0.083096\n",
      "66 \t\t 0.073315\n",
      "67 \t\t 0.064572\n",
      "68 \t\t 0.056793\n",
      "69 \t\t 0.049899\n",
      "70 \t\t 0.043810\n",
      "71 \t\t 0.038447\n",
      "72 \t\t 0.033736\n",
      "73 \t\t 0.029605\n",
      "74 \t\t 0.025987\n",
      "75 \t\t 0.022823\n",
      "76 \t\t 0.020056\n",
      "77 \t\t 0.017638\n",
      "78 \t\t 0.015524\n",
      "79 \t\t 0.013676\n",
      "80 \t\t 0.012059\n",
      "81 \t\t 0.010643\n",
      "82 \t\t 0.009402\n",
      "83 \t\t 0.008314\n",
      "84 \t\t 0.007358\n",
      "85 \t\t 0.006518\n",
      "86 \t\t 0.005779\n",
      "87 \t\t 0.005127\n",
      "88 \t\t 0.004553\n",
      "89 \t\t 0.004045\n",
      "90 \t\t 0.003597\n",
      "91 \t\t 0.003200\n",
      "92 \t\t 0.002848\n",
      "93 \t\t 0.002537\n",
      "94 \t\t 0.002260\n",
      "95 \t\t 0.002015\n",
      "96 \t\t 0.001797\n",
      "97 \t\t 0.001603\n",
      "98 \t\t 0.001430\n",
      "99 \t\t 0.001277\n",
      "100 \t\t 0.001140\n",
      "101 \t\t 0.001018\n",
      "102 \t\t 0.000909\n",
      "103 \t\t 0.000812\n",
      "104 \t\t 0.000726\n",
      "105 \t\t 0.000649\n",
      "106 \t\t 0.000580\n",
      "107 \t\t 0.000518\n",
      "108 \t\t 0.000463\n",
      "109 \t\t 0.000414\n",
      "110 \t\t 0.000370\n",
      "111 \t\t 0.000331\n",
      "112 \t\t 0.000296\n",
      "113 \t\t 0.000265\n",
      "114 \t\t 0.000237\n",
      "115 \t\t 0.000212\n",
      "116 \t\t 0.000189\n",
      "117 \t\t 0.000169\n",
      "118 \t\t 0.000152\n",
      "119 \t\t 0.000136\n",
      "120 \t\t 0.000121\n",
      "121 \t\t 0.000108\n",
      "122 \t\t 0.000097\n",
      "123 \t\t 0.000087\n",
      "124 \t\t 0.000078\n",
      "125 \t\t 0.000069\n",
      "126 \t\t 0.000062\n",
      "127 \t\t 0.000056\n",
      "128 \t\t 0.000050\n",
      "129 \t\t 0.000044\n",
      "130 \t\t 0.000040\n",
      "131 \t\t 0.000036\n",
      "132 \t\t 0.000032\n",
      "133 \t\t 0.000028\n",
      "134 \t\t 0.000025\n",
      "135 \t\t 0.000023\n",
      "136 \t\t 0.000020\n",
      "137 \t\t 0.000018\n",
      "138 \t\t 0.000016\n",
      "139 \t\t 0.000015\n",
      "140 \t\t 0.000013\n",
      "141 \t\t 0.000012\n",
      "142 \t\t 0.000010\n",
      "143 \t\t 0.000009\n",
      "144 \t\t 0.000008\n",
      "145 \t\t 0.000007\n",
      "146 \t\t 0.000007\n",
      "147 \t\t 0.000006\n",
      "148 \t\t 0.000005\n",
      "149 \t\t 0.000005\n",
      "150 \t\t 0.000004\n",
      "151 \t\t 0.000004\n",
      "152 \t\t 0.000003\n",
      "153 \t\t 0.000003\n",
      "154 \t\t 0.000003\n",
      "155 \t\t 0.000002\n",
      "156 \t\t 0.000002\n",
      "157 \t\t 0.000002\n",
      "158 \t\t 0.000002\n",
      "159 \t\t 0.000002\n",
      "160 \t\t 0.000001\n",
      "161 \t\t 0.000001\n",
      "162 \t\t 0.000001\n",
      "163 \t\t 0.000001\n",
      "164 \t\t 0.000001\n",
      "165 \t\t 0.000001\n",
      "166 \t\t 0.000001\n",
      "167 \t\t 0.000001\n",
      "168 \t\t 0.000001\n",
      "169 \t\t 0.000001\n",
      "170 \t\t 0.000000\n",
      "171 \t\t 0.000000\n",
      "172 \t\t 0.000000\n",
      "173 \t\t 0.000000\n",
      "174 \t\t 0.000000\n",
      "175 \t\t 0.000000\n",
      "176 \t\t 0.000000\n",
      "177 \t\t 0.000000\n",
      "178 \t\t 0.000000\n",
      "179 \t\t 0.000000\n",
      "180 \t\t 0.000000\n",
      "181 \t\t 0.000000\n",
      "182 \t\t 0.000000\n",
      "183 \t\t 0.000000\n",
      "184 \t\t 0.000000\n",
      "185 \t\t 0.000000\n",
      "186 \t\t 0.000000\n",
      "187 \t\t 0.000000\n",
      "188 \t\t 0.000000\n",
      "189 \t\t 0.000000\n",
      "190 \t\t 0.000000\n",
      "191 \t\t 0.000000\n",
      "192 \t\t 0.000000\n",
      "193 \t\t 0.000000\n",
      "194 \t\t 0.000000\n",
      "195 \t\t 0.000000\n",
      "196 \t\t 0.000000\n",
      "197 \t\t 0.000000\n",
      "198 \t\t 0.000000\n",
      "199 \t\t 0.000000\n",
      "200 \t\t 0.000000\n",
      "201 \t\t 0.000000\n",
      "202 \t\t 0.000000\n",
      "203 \t\t 0.000000\n",
      "204 \t\t 0.000000\n",
      "205 \t\t 0.000000\n",
      "206 \t\t 0.000000\n",
      "207 \t\t 0.000000\n",
      "208 \t\t 0.000000\n",
      "209 \t\t 0.000000\n",
      "210 \t\t 0.000000\n",
      "211 \t\t 0.000000\n",
      "212 \t\t 0.000000\n",
      "213 \t\t 0.000000\n",
      "214 \t\t 0.000000\n",
      "215 \t\t 0.000000\n",
      "216 \t\t 0.000000\n",
      "217 \t\t 0.000000\n",
      "218 \t\t 0.000000\n",
      "219 \t\t 0.000000\n",
      "220 \t\t 0.000000\n",
      "221 \t\t 0.000000\n",
      "222 \t\t 0.000000\n",
      "223 \t\t 0.000000\n",
      "224 \t\t 0.000000\n",
      "225 \t\t 0.000000\n",
      "226 \t\t 0.000000\n",
      "227 \t\t 0.000000\n",
      "228 \t\t 0.000000\n",
      "229 \t\t 0.000000\n",
      "230 \t\t 0.000000\n",
      "231 \t\t 0.000000\n",
      "232 \t\t 0.000000\n",
      "233 \t\t 0.000000\n",
      "234 \t\t 0.000000\n",
      "235 \t\t 0.000000\n",
      "236 \t\t 0.000000\n",
      "237 \t\t 0.000000\n",
      "238 \t\t 0.000000\n",
      "239 \t\t 0.000000\n",
      "240 \t\t 0.000000\n",
      "241 \t\t 0.000000\n",
      "242 \t\t 0.000000\n",
      "243 \t\t 0.000000\n",
      "244 \t\t 0.000000\n",
      "245 \t\t 0.000000\n",
      "246 \t\t 0.000000\n",
      "247 \t\t 0.000000\n",
      "248 \t\t 0.000000\n",
      "249 \t\t 0.000000\n",
      "250 \t\t 0.000000\n"
     ]
    }
   ],
   "source": [
    "#use your function with 4 latent features, lr of 0.005 and 250 iterations\n",
    "user_mat, movie_mat = FunkSVD(ratings_mat, latent_features=4, learning_rate=0.005, iters=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.99999702  9.99999856  9.99999945 10.00000281]\n",
      " [ 9.99999711  3.99999867  8.99999952 10.00000271]\n",
      " [ 8.0000065   9.00000313 10.00000122  4.99999395]\n",
      " [ 8.99999796  7.99999905  9.99999964 10.00000191]\n",
      " [ 9.99999735  4.99999882  8.99999958  9.00000248]\n",
      " [ 6.00001711  4.00000823 10.00000315  5.99998396]\n",
      " [ 8.99999375  7.99999686  9.99999872  9.00000584]\n",
      " [10.00000914  5.00000429  9.0000016   7.99999146]\n",
      " [ 6.99998869  7.99999446  9.99999781  8.00001056]\n",
      " [ 8.99997929  4.99999008  8.99999621  7.00001938]\n",
      " [ 9.00000981  8.00000492 10.00000203  7.99999087]\n",
      " [ 8.999996    9.99999823  9.9999994   9.00000376]\n",
      " [10.00000517  9.0000026  10.00000109  7.99999521]\n",
      " [ 5.0000011   8.00000065  5.00000032  7.99999899]\n",
      " [10.00001448  8.00000696 10.00000269  9.99998648]\n",
      " [ 9.          8.99999982  9.99999983  9.99999999]\n",
      " [ 8.99999024  7.9999952   7.99999809  8.00000913]\n",
      " [10.00000456  8.00000224  1.00000092  9.99999581]\n",
      " [ 5.00000212  6.000001   10.00000037  9.99999798]\n",
      " [ 7.9999933   6.99999675  9.99999871  7.00000623]]\n",
      "[[10. 10. 10. 10.]\n",
      " [10.  4.  9. 10.]\n",
      " [ 8.  9. 10.  5.]\n",
      " [ 9.  8. 10. 10.]\n",
      " [10.  5.  9.  9.]\n",
      " [ 6.  4. 10.  6.]\n",
      " [ 9.  8. 10.  9.]\n",
      " [10.  5.  9.  8.]\n",
      " [ 7.  8. 10.  8.]\n",
      " [ 9.  5.  9.  7.]\n",
      " [ 9.  8. 10.  8.]\n",
      " [ 9. 10. 10.  9.]\n",
      " [10.  9. 10.  8.]\n",
      " [ 5.  8.  5.  8.]\n",
      " [10.  8. 10. 10.]\n",
      " [ 9.  9. 10. 10.]\n",
      " [ 9.  8.  8.  8.]\n",
      " [10.  8.  1. 10.]\n",
      " [ 5.  6. 10. 10.]\n",
      " [ 8.  7. 10.  7.]]\n"
     ]
    }
   ],
   "source": [
    "#Compare the predicted and actual results\n",
    "print(np.dot(user_mat, movie_mat))\n",
    "print(ratings_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**请在此处填写你的结论。**\n",
    "**In this case, we were able to completely reconstruct the item-movie matrix to obtain an essentially 0 mean squared error. I obtained 0 MSE on iteration 165.**\n",
    "\n",
    "上次在此矩阵里放入 **np.nan** 值时，python 中的整个 SVD 算法崩溃了。我们看看使用你的 FunkSVD 函数是否依然会这样。在以下单元格中，我在你的 numpy 数组的第一个单元格中放入了一个 NaN 值。  \n",
    "\n",
    "`4.` 假设潜在特征有 4 个，学习速率为 0.005，并且迭代 250 次。你能够运行你的 SVD 并且不崩溃吗（内置的 python 方法会崩溃）？你获得了 NaN 值的预测值吗？缺失值的预测是多少？请在以下单元格中回答这些问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[nan, 10., 10., 10.],\n",
       "        [10.,  4.,  9., 10.],\n",
       "        [ 8.,  9., 10.,  5.],\n",
       "        [ 9.,  8., 10., 10.],\n",
       "        [10.,  5.,  9.,  9.],\n",
       "        [ 6.,  4., 10.,  6.],\n",
       "        [ 9.,  8., 10.,  9.],\n",
       "        [10.,  5.,  9.,  8.],\n",
       "        [ 7.,  8., 10.,  8.],\n",
       "        [ 9.,  5.,  9.,  7.],\n",
       "        [ 9.,  8., 10.,  8.],\n",
       "        [ 9., 10., 10.,  9.],\n",
       "        [10.,  9., 10.,  8.],\n",
       "        [ 5.,  8.,  5.,  8.],\n",
       "        [10.,  8., 10., 10.],\n",
       "        [ 9.,  9., 10., 10.],\n",
       "        [ 9.,  8.,  8.,  8.],\n",
       "        [10.,  8.,  1., 10.],\n",
       "        [ 5.,  6., 10., 10.],\n",
       "        [ 8.,  7., 10.,  7.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we are placing a nan into our original subset matrix\n",
    "ratings_mat[0, 0] = np.nan\n",
    "ratings_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 52.152034\n",
      "2 \t\t 23.133246\n",
      "3 \t\t 6.445888\n",
      "4 \t\t 3.143671\n",
      "5 \t\t 2.710574\n",
      "6 \t\t 2.604873\n",
      "7 \t\t 2.555339\n",
      "8 \t\t 2.518622\n",
      "9 \t\t 2.484467\n",
      "10 \t\t 2.450205\n",
      "11 \t\t 2.415171\n",
      "12 \t\t 2.379282\n",
      "13 \t\t 2.342630\n",
      "14 \t\t 2.305363\n",
      "15 \t\t 2.267621\n",
      "16 \t\t 2.229500\n",
      "17 \t\t 2.191022\n",
      "18 \t\t 2.152108\n",
      "19 \t\t 2.112562\n",
      "20 \t\t 2.072059\n",
      "21 \t\t 2.030142\n",
      "22 \t\t 1.986232\n",
      "23 \t\t 1.939644\n",
      "24 \t\t 1.889618\n",
      "25 \t\t 1.835360\n",
      "26 \t\t 1.776091\n",
      "27 \t\t 1.711121\n",
      "28 \t\t 1.639929\n",
      "29 \t\t 1.562250\n",
      "30 \t\t 1.478171\n",
      "31 \t\t 1.388210\n",
      "32 \t\t 1.293364\n",
      "33 \t\t 1.195107\n",
      "34 \t\t 1.095317\n",
      "35 \t\t 0.996129\n",
      "36 \t\t 0.899730\n",
      "37 \t\t 0.808128\n",
      "38 \t\t 0.722936\n",
      "39 \t\t 0.645234\n",
      "40 \t\t 0.575513\n",
      "41 \t\t 0.513720\n",
      "42 \t\t 0.459375\n",
      "43 \t\t 0.411721\n",
      "44 \t\t 0.369877\n",
      "45 \t\t 0.332955\n",
      "46 \t\t 0.300144\n",
      "47 \t\t 0.270756\n",
      "48 \t\t 0.244234\n",
      "49 \t\t 0.220150\n",
      "50 \t\t 0.198183\n",
      "51 \t\t 0.178094\n",
      "52 \t\t 0.159710\n",
      "53 \t\t 0.142898\n",
      "54 \t\t 0.127555\n",
      "55 \t\t 0.113592\n",
      "56 \t\t 0.100930\n",
      "57 \t\t 0.089490\n",
      "58 \t\t 0.079196\n",
      "59 \t\t 0.069969\n",
      "60 \t\t 0.061729\n",
      "61 \t\t 0.054397\n",
      "62 \t\t 0.047894\n",
      "63 \t\t 0.042141\n",
      "64 \t\t 0.037065\n",
      "65 \t\t 0.032596\n",
      "66 \t\t 0.028667\n",
      "67 \t\t 0.025217\n",
      "68 \t\t 0.022190\n",
      "69 \t\t 0.019537\n",
      "70 \t\t 0.017211\n",
      "71 \t\t 0.015173\n",
      "72 \t\t 0.013385\n",
      "73 \t\t 0.011817\n",
      "74 \t\t 0.010441\n",
      "75 \t\t 0.009233\n",
      "76 \t\t 0.008170\n",
      "77 \t\t 0.007236\n",
      "78 \t\t 0.006413\n",
      "79 \t\t 0.005687\n",
      "80 \t\t 0.005047\n",
      "81 \t\t 0.004481\n",
      "82 \t\t 0.003982\n",
      "83 \t\t 0.003539\n",
      "84 \t\t 0.003148\n",
      "85 \t\t 0.002801\n",
      "86 \t\t 0.002493\n",
      "87 \t\t 0.002220\n",
      "88 \t\t 0.001978\n",
      "89 \t\t 0.001762\n",
      "90 \t\t 0.001571\n",
      "91 \t\t 0.001400\n",
      "92 \t\t 0.001249\n",
      "93 \t\t 0.001114\n",
      "94 \t\t 0.000994\n",
      "95 \t\t 0.000887\n",
      "96 \t\t 0.000791\n",
      "97 \t\t 0.000706\n",
      "98 \t\t 0.000630\n",
      "99 \t\t 0.000563\n",
      "100 \t\t 0.000502\n",
      "101 \t\t 0.000448\n",
      "102 \t\t 0.000400\n",
      "103 \t\t 0.000357\n",
      "104 \t\t 0.000319\n",
      "105 \t\t 0.000285\n",
      "106 \t\t 0.000254\n",
      "107 \t\t 0.000227\n",
      "108 \t\t 0.000203\n",
      "109 \t\t 0.000181\n",
      "110 \t\t 0.000162\n",
      "111 \t\t 0.000145\n",
      "112 \t\t 0.000129\n",
      "113 \t\t 0.000115\n",
      "114 \t\t 0.000103\n",
      "115 \t\t 0.000092\n",
      "116 \t\t 0.000082\n",
      "117 \t\t 0.000073\n",
      "118 \t\t 0.000066\n",
      "119 \t\t 0.000058\n",
      "120 \t\t 0.000052\n",
      "121 \t\t 0.000047\n",
      "122 \t\t 0.000042\n",
      "123 \t\t 0.000037\n",
      "124 \t\t 0.000033\n",
      "125 \t\t 0.000030\n",
      "126 \t\t 0.000026\n",
      "127 \t\t 0.000024\n",
      "128 \t\t 0.000021\n",
      "129 \t\t 0.000019\n",
      "130 \t\t 0.000017\n",
      "131 \t\t 0.000015\n",
      "132 \t\t 0.000013\n",
      "133 \t\t 0.000012\n",
      "134 \t\t 0.000011\n",
      "135 \t\t 0.000010\n",
      "136 \t\t 0.000009\n",
      "137 \t\t 0.000008\n",
      "138 \t\t 0.000007\n",
      "139 \t\t 0.000006\n",
      "140 \t\t 0.000005\n",
      "141 \t\t 0.000005\n",
      "142 \t\t 0.000004\n",
      "143 \t\t 0.000004\n",
      "144 \t\t 0.000003\n",
      "145 \t\t 0.000003\n",
      "146 \t\t 0.000003\n",
      "147 \t\t 0.000002\n",
      "148 \t\t 0.000002\n",
      "149 \t\t 0.000002\n",
      "150 \t\t 0.000002\n",
      "151 \t\t 0.000002\n",
      "152 \t\t 0.000001\n",
      "153 \t\t 0.000001\n",
      "154 \t\t 0.000001\n",
      "155 \t\t 0.000001\n",
      "156 \t\t 0.000001\n",
      "157 \t\t 0.000001\n",
      "158 \t\t 0.000001\n",
      "159 \t\t 0.000001\n",
      "160 \t\t 0.000001\n",
      "161 \t\t 0.000001\n",
      "162 \t\t 0.000000\n",
      "163 \t\t 0.000000\n",
      "164 \t\t 0.000000\n",
      "165 \t\t 0.000000\n",
      "166 \t\t 0.000000\n",
      "167 \t\t 0.000000\n",
      "168 \t\t 0.000000\n",
      "169 \t\t 0.000000\n",
      "170 \t\t 0.000000\n",
      "171 \t\t 0.000000\n",
      "172 \t\t 0.000000\n",
      "173 \t\t 0.000000\n",
      "174 \t\t 0.000000\n",
      "175 \t\t 0.000000\n",
      "176 \t\t 0.000000\n",
      "177 \t\t 0.000000\n",
      "178 \t\t 0.000000\n",
      "179 \t\t 0.000000\n",
      "180 \t\t 0.000000\n",
      "181 \t\t 0.000000\n",
      "182 \t\t 0.000000\n",
      "183 \t\t 0.000000\n",
      "184 \t\t 0.000000\n",
      "185 \t\t 0.000000\n",
      "186 \t\t 0.000000\n",
      "187 \t\t 0.000000\n",
      "188 \t\t 0.000000\n",
      "189 \t\t 0.000000\n",
      "190 \t\t 0.000000\n",
      "191 \t\t 0.000000\n",
      "192 \t\t 0.000000\n",
      "193 \t\t 0.000000\n",
      "194 \t\t 0.000000\n",
      "195 \t\t 0.000000\n",
      "196 \t\t 0.000000\n",
      "197 \t\t 0.000000\n",
      "198 \t\t 0.000000\n",
      "199 \t\t 0.000000\n",
      "200 \t\t 0.000000\n",
      "201 \t\t 0.000000\n",
      "202 \t\t 0.000000\n",
      "203 \t\t 0.000000\n",
      "204 \t\t 0.000000\n",
      "205 \t\t 0.000000\n",
      "206 \t\t 0.000000\n",
      "207 \t\t 0.000000\n",
      "208 \t\t 0.000000\n",
      "209 \t\t 0.000000\n",
      "210 \t\t 0.000000\n",
      "211 \t\t 0.000000\n",
      "212 \t\t 0.000000\n",
      "213 \t\t 0.000000\n",
      "214 \t\t 0.000000\n",
      "215 \t\t 0.000000\n",
      "216 \t\t 0.000000\n",
      "217 \t\t 0.000000\n",
      "218 \t\t 0.000000\n",
      "219 \t\t 0.000000\n",
      "220 \t\t 0.000000\n",
      "221 \t\t 0.000000\n",
      "222 \t\t 0.000000\n",
      "223 \t\t 0.000000\n",
      "224 \t\t 0.000000\n",
      "225 \t\t 0.000000\n",
      "226 \t\t 0.000000\n",
      "227 \t\t 0.000000\n",
      "228 \t\t 0.000000\n",
      "229 \t\t 0.000000\n",
      "230 \t\t 0.000000\n",
      "231 \t\t 0.000000\n",
      "232 \t\t 0.000000\n",
      "233 \t\t 0.000000\n",
      "234 \t\t 0.000000\n",
      "235 \t\t 0.000000\n",
      "236 \t\t 0.000000\n",
      "237 \t\t 0.000000\n",
      "238 \t\t 0.000000\n",
      "239 \t\t 0.000000\n",
      "240 \t\t 0.000000\n",
      "241 \t\t 0.000000\n",
      "242 \t\t 0.000000\n",
      "243 \t\t 0.000000\n",
      "244 \t\t 0.000000\n",
      "245 \t\t 0.000000\n",
      "246 \t\t 0.000000\n",
      "247 \t\t 0.000000\n",
      "248 \t\t 0.000000\n",
      "249 \t\t 0.000000\n",
      "250 \t\t 0.000000\n"
     ]
    }
   ],
   "source": [
    "# run SVD on the matrix with the missing value\n",
    "#use your function with 4 latent features, lr of 0.005 and 250 iterations\n",
    "user_mat, movie_mat = FunkSVD(ratings_mat, latent_features=4, learning_rate=0.005, iters=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted value for the missing rating is 10.108588725589916:\n",
      "\n",
      "The actual value for the missing rating is nan:\n",
      "\n",
      "That's right! You just predicted a rating for a user-movie pair that was never rated!\n",
      "But if you look in the original matrix, this was actually a value of 10. Not bad!\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to see if you were able to predict for the missing value\n",
    "preds = np.dot(user_mat, movie_mat)\n",
    "print(\"The predicted value for the missing rating is {}:\".format(preds[0,0]))\n",
    "print()\n",
    "print(\"The actual value for the missing rating is {}:\".format(ratings_mat[0,0]))\n",
    "print()\n",
    "assert np.isnan(preds[0,0]) == False\n",
    "print(\"That's right! You just predicted a rating for a user-movie pair that was never rated!\")\n",
    "print(\"But if you look in the original matrix, this was actually a value of 10. Not bad!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面扩展到更真实的例子上。遗憾的是，依然不建议在本地机器上对整个用户-电影矩阵运行此函数。但是，我们能够查看这个示例扩展到 1000 个用户的情况。在上述部分，你使用了一个非常小的数据子集，并且没有缺失值。\n",
    "\n",
    "`5.` 考虑到此矩阵的大小，运行时间会比较长。假设超参数如下所示：潜在特征为 4 个，学习速率为0.005，迭代次数为20。运行时间会很久，吃点东西，散散步吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 23.116482\n",
      "2 \t\t 10.722545\n",
      "3 \t\t 7.384865\n",
      "4 \t\t 5.708581\n",
      "5 \t\t 4.643374\n",
      "6 \t\t 3.894543\n",
      "7 \t\t 3.337359\n",
      "8 \t\t 2.906582\n",
      "9 \t\t 2.564096\n",
      "10 \t\t 2.286160\n",
      "11 \t\t 2.057181\n",
      "12 \t\t 1.866413\n",
      "13 \t\t 1.706107\n",
      "14 \t\t 1.570440\n",
      "15 \t\t 1.454894\n",
      "16 \t\t 1.355878\n",
      "17 \t\t 1.270498\n",
      "18 \t\t 1.196401\n",
      "19 \t\t 1.131667\n",
      "20 \t\t 1.074731\n"
     ]
    }
   ],
   "source": [
    "# Setting up a matrix of the first 1000 users with movie ratings\n",
    "first_1000_users = np.matrix(user_by_movie.head(1000))\n",
    "\n",
    "# perform funkSVD on the matrix of the top 1000 users\n",
    "#fit to 1000 users with 4 latent features, lr of 0.005, and 20 iterations\n",
    "user_mat, movie_mat = FunkSVD(first_1000_users, latent_features=4, learning_rate=0.005, iters=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`6.` 现在你已经获得了每个用户-电影对的预测值，请根据你的结果回答几个问题。请在以下每个变量对应的括号里填写正确的值，并使用以下测试检测你的答案。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of actual ratings in the first_1000_users is 10852.\n",
      "\n",
      "The number of ratings made for user-movie pairs that didn't have ratings is 31234148\n"
     ]
    }
   ],
   "source": [
    "# Replace each of the comments below with the correct values\n",
    "# How many actual ratings exist in first_1000_users\n",
    "num_ratings = np.count_nonzero(~np.isnan(first_1000_users))\n",
    "print(\"The number of actual ratings in the first_1000_users is {}.\".format(num_ratings))\n",
    "print()\n",
    "\n",
    "# How many ratings did we make for user-movie pairs that didn't actually have ratings\n",
    "ratings_for_missing = first_1000_users.shape[0]*first_1000_users.shape[1] - num_ratings \n",
    "print(\"The number of ratings made for user-movie pairs that didn't have ratings is {}\".format(ratings_for_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nice job!  Looks like you have predictions made for all the missing user-movie pairs! But I still have one question... How good are they?\n"
     ]
    }
   ],
   "source": [
    "# Test your results against the solution\n",
    "assert num_ratings == 10852, \"Oops!  The number of actual ratings doesn't quite look right.\"\n",
    "assert ratings_for_missing == 31234148, \"Oops!  The number of movie-user pairs that you made ratings for that didn't actually have ratings doesn't look right.\"\n",
    "\n",
    "# Make sure you made predictions on all the missing user-movie pairs\n",
    "preds = np.dot(user_mat, movie_mat)\n",
    "assert np.isnan(preds).sum() == 0\n",
    "print(\"Nice job!  Looks like you have predictions made for all the missing user-movie pairs! But I still have one question... How good are they?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
